{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overhead\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment parameters\n",
    "\n",
    "FRAME_TIME = 0.1  # time interval\n",
    "GRAVITY_ACCEL = 0.2  # gravity constant\n",
    "BOOST_ACCEL = 0.55  # thrust constant\n",
    "DRAG_COEFF = 0.25 # Drag coefficient\n",
    "S = 0.1 # Surface Area of rocket\n",
    "RHO = 0.1225 # Air Density at sea level\n",
    "FPA_GAIN = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define system dynamics\n",
    "# Notes: \n",
    "# 0. You only need to modify the \"forward\" function\n",
    "# 1. All variables in \"forward\" need to be PyTorch tensors.\n",
    "# 2. All math operations in \"forward\" has to be differentiable, e.g., default PyTorch functions.\n",
    "# 3. Do not use inplace operations, e.g., x += 1. Please see the following section for an example that does not work.\n",
    "\n",
    "class Dynamics(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dynamics, self).__init__()\n",
    "    @staticmethod\n",
    "    def forward(state, action):\n",
    "        \"\"\"\n",
    "        action[0]: thrust control\n",
    "        action[1]: fpa control\n",
    "        state[0] = x\n",
    "        state[1] = x_dot\n",
    "        state[2] = fpa\n",
    "        state[3] = fpa_dot\n",
    "        ###\n",
    "        fpa_dot(t+1) = fpa_dot(t) + (gsin(fpa) - action[1])*dt\n",
    "        \"\"\"\n",
    "        delta_x_dot = (t.tensor([0.,(GRAVITY_ACCEL*t.cos(state.detach()[2])) - (0.5*RHO*(state.detach()[1]**2)*S*DRAG_COEFF) - BOOST_ACCEL*action[0], 0., 0.])*FRAME_TIME) - (t.tensor([0., 1., 0., 0.])*BOOST_ACCEL*action[0]*FRAME_TIME)\n",
    "        delta_fpa_dot = (t.tensor([0., 0., 0., (GRAVITY_ACCEL*t.sin(state.detach()[2]))])*FRAME_TIME) - (t.tensor([0., 0., 0., 1.])*FPA_GAIN*action[1]*FRAME_TIME)\n",
    "        step_mat = t.tensor([[1., FRAME_TIME, 0., 0.],\n",
    "                             [0., 1., 0., 0.,],\n",
    "                             [0., 0., 1., FRAME_TIME],\n",
    "                             [0., 0., 0., 1.]\n",
    "                            ])\n",
    "        state = t.matmul(step_mat, state)\n",
    "        state = state + delta_x_dot + delta_fpa_dot\n",
    "\n",
    "\n",
    "        # delta_state_gravity = t.tensor([0., GRAVITY_ACCEL * FRAME_TIME]) \n",
    "        # delta_state_drag = t.tensor([0., -0.5*RHO*S*DRAG_COEFF*FRAME_TIME*(state.detach().clone()[1]**2)])\n",
    "        # delta_state = BOOST_ACCEL * FRAME_TIME * t.tensor([0., -1.]) * action\n",
    "\n",
    "        # step_mat = t.tensor([[1., FRAME_TIME],\n",
    "        #                     [0., 1.]])\n",
    "        # state = t.matmul(step_mat, state)\n",
    "        # state = state + delta_state + delta_state_gravity + delta_state_drag\n",
    "        \n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a deterministic controller\n",
    "# Note:\n",
    "# 0. You only need to change the network architecture in \"__init__\"\n",
    "# 1. nn.Sigmoid outputs values from 0 to 1, nn.Tanh from -1 to 1\n",
    "# 2. You have all the freedom to make the network wider (by increasing \"dim_hidden\") or deeper (by adding more lines to nn.Sequential)\n",
    "# 3. Always start with something simple\n",
    "\n",
    "class Controller(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_input, dim_hidden, dim_output):\n",
    "        \"\"\"\n",
    "        dim_input: # of system states\n",
    "        dim_output: # of actions\n",
    "        dim_hidden: up to you\n",
    "        \"\"\"\n",
    "        super(Controller, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(dim_input, dim_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(dim_hidden, 48),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(48, 64),\n",
    "            nn.Linear(64, dim_output),\n",
    "            # You can add more layers here\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        action = self.network(state)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simulator that rolls out x(1), x(2), ..., x(T)\n",
    "# Note:\n",
    "# 0. Need to change \"initialize_state\" to optimize the controller over a distribution of initial states\n",
    "# 1. self.action_trajectory and self.state_trajectory stores the action and state trajectories along time\n",
    "\n",
    "class Simulation(nn.Module):\n",
    "\n",
    "    def __init__(self, controller, dynamics, T):\n",
    "        super(Simulation, self).__init__()\n",
    "        self.state = self.initialize_state()\n",
    "        self.controller = controller\n",
    "        self.dynamics = dynamics\n",
    "        self.T = T\n",
    "        self.action_trajectory = []\n",
    "        self.state_trajectory = []\n",
    "\n",
    "    def forward(self, state):\n",
    "        self.action_trajectory = []\n",
    "        self.state_trajectory = []\n",
    "        for _ in range(T):\n",
    "            action = self.controller.forward(state)\n",
    "            state = self.dynamics.forward(state, action)\n",
    "            self.action_trajectory.append(action)\n",
    "            self.state_trajectory.append(state)\n",
    "        return self.error(state)\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_state():\n",
    "        state = [1., 0., 1., 0.] # TODO: need batch of initial states\n",
    "        return t.tensor(state, requires_grad=False).float()\n",
    "\n",
    "    def error(self, state):\n",
    "        return state[0]**2 + state[1]**2 + state[2]**2 + state[3]**2\n",
    "        # return state[0]**2 + state[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "# Note:\n",
    "# 0. LBFGS is a good choice if you don't have a large batch size (i.e., a lot of initial states to consider simultaneously)\n",
    "# 1. You can also try SGD and other momentum-based methods implemented in PyTorch\n",
    "# 2. You will need to customize \"visualize\"\n",
    "# 3. loss.backward is where the gradient is calculated (d_loss/d_variables)\n",
    "# 4. self.optimizer.step(closure) is where gradient descent is done\n",
    "\n",
    "class Optimize:\n",
    "    def __init__(self, simulation):\n",
    "        self.simulation = simulation\n",
    "        self.parameters = simulation.controller.parameters()\n",
    "        self.optimizer = optim.LBFGS(self.parameters, lr=0.01, line_search_fn='strong_wolfe')\n",
    "        # self.scheduler = optim.lr_scheduler.StepLR(optimizer = self.optimizer, step_size = 10,gamma = 0.5)\n",
    "\n",
    "    def step(self):\n",
    "        def closure():\n",
    "            loss = self.simulation(self.simulation.state)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.parameters\n",
    "            return loss\n",
    "        self.optimizer.step(closure)\n",
    "        # self.scheduler.step()\n",
    "        return closure()\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        best_loss = 1e10\n",
    "        for epoch in range(epochs):\n",
    "            loss = self.step()\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_state_trajectory = self.simulation.state_trajectory\n",
    "                best_action_trajectory = self.simulation.action_trajectory\n",
    "                print(\"Best loss:\", best_loss.data, \"Saving trajectory data...\")\n",
    "            if epoch%1 == 0: \n",
    "                print('[%d] loss: %.3f' % (epoch + 1, loss))\n",
    "                if epoch == epochs -1 or best_loss == 0.:\n",
    "                    self.visualize(best_state_trajectory, best_action_trajectory)\n",
    "                    print(\"Final state vector for the best trajectory: \", best_state_trajectory[99])\n",
    "                    break\n",
    "\n",
    "    def visualize(self, state_trajectory = None, action_trajectory = None):\n",
    "        data = np.array([state_trajectory[i].detach().numpy() for i in range(self.simulation.T)])\n",
    "        action_data = np.array([action_trajectory[i].detach().numpy() for i in range(self.simulation.T)])\n",
    "        x = data[:, 0]\n",
    "        x_dot = data[:, 1]\n",
    "        fpa = data[:, 2]\n",
    "        fpa_dot = data[:, 3]\n",
    "        plt.plot(x)\n",
    "        plt.xlabel('Time_Steps')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.show()\n",
    "        plt.plot(x_dot)\n",
    "        plt.xlabel('Time_step')\n",
    "        plt.ylabel('Speed')\n",
    "        plt.show()\n",
    "        plt.plot(fpa)\n",
    "        plt.xlabel('Time_step')\n",
    "        plt.ylabel('Flight Path Angle')\n",
    "        plt.show()\n",
    "        plt.plot(fpa_dot)\n",
    "        plt.xlabel('Time_step')\n",
    "        plt.ylabel('Angular speed')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "line search function is not supported yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-658-f11fc6f9838b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# define simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# define optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# solve the optimization problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-657-67942d05612f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-657-67942d05612f>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m# self.scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mmax_eval\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmaximal\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mevaluations\u001b[0m \u001b[0mper\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mstep\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mtolerance_grad\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtermination\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0mon\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0morder\u001b[0m \u001b[0moptimality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: line search function is not supported yet"
     ]
    }
   ],
   "source": [
    "# Now it's time to run the code!\n",
    "\n",
    "T = 100  # number of time steps\n",
    "dim_input = 4  # state space dimensions\n",
    "dim_hidden = 24  # latent dimensions\n",
    "dim_output = 2  # action space dimensions\n",
    "d = Dynamics()  # define dynamics\n",
    "c = Controller(dim_input, dim_hidden, dim_output)  # define controller\n",
    "s = Simulation(c, d, T)  # define simulation\n",
    "o = Optimize(s)  # define optimizer\n",
    "o.train(100)  # solve the optimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of the problem:** \\\n",
    "The formulation of the rocket landing problem has been extended to include a flight path angle controller and aerodynamic drag. \\\n",
    "To test the controller in a range of situations, a batch of initial states were sampled from a normal distribution:\n",
    "$$\n",
    "x_{ij} \\sim N(\\mu_j, \\sigma_j), i = 1, ... ,N \\space j = 1, ... , M \n",
    "$$\n",
    "In this case, we have N = 5 batches and M = 4 states. \\\n",
    "Each of the states are updated according to the forces external to the rocket and the forces exerted by the control input. The state variable formulation for this problem is as follows:\n",
    "$$\n",
    "x(t+1) = x(t) + \\dot x(t)dt \\\\\n",
    "\\dot x(t+1) = \\dot x(t) + \\ddot x(t)dt \\\\\n",
    "\\nu(t+1) = x(t) + \\dot \\nu(t)dt \\\\\n",
    "\\dot \\nu(t+1) = \\dot \\nu(t) + \\ddot \\nu(t)dt \\\\\n",
    "$$\n",
    "<center>\n",
    "\n",
    "![Force diagram](FBD.png)\n",
    "\n",
    "</center>\n",
    "The update for the velocity and flight path angle are given as follows, assuming a constant mass system:\n",
    "\n",
    "$$\n",
    "d\\dot x = (gcos(\\nu) - a_{drag} - a_{thrust})dt \\\\\n",
    "d\\dot \\nu = (gsin(\\nu) - a_{cSurf})dt\n",
    "$$\n",
    "$ a_{cSurf} $ is the acceleration produced by the control input for changing the flight path angle. The "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01ef4f39dfdb6b9ac45b62b4072444b380e64c61157c7fbd20fb951243ee6c76"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
